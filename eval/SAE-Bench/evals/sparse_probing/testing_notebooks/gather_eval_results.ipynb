{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional to download multiple layers conveniently\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "repo_id = \"canrager/lm_sae\"\n",
    "\n",
    "release_names = [\n",
    "    \"sae_bench_gemma-2-2b_sweep_standard_ctx128_ef2_0824\",\n",
    "    \"sae_bench_gemma-2-2b_sweep_standard_ctx128_ef8_0824\",\n",
    "    \"sae_bench_gemma-2-2b_sweep_topk_ctx128_ef2_0824\",\n",
    "    \"sae_bench_gemma-2-2b_sweep_topk_ctx128_ef8_0824\",\n",
    "    \"sae_bench_pythia70m_sweep_gated_ctx128_0730\",\n",
    "    \"sae_bench_pythia70m_sweep_panneal_ctx128_0730\",\n",
    "    \"sae_bench_pythia70m_sweep_standard_ctx128_0712\",\n",
    "    \"sae_bench_pythia70m_sweep_topk_ctx128_0730\",\n",
    "]\n",
    "\n",
    "# for release_name in release_names:\n",
    "#     folder_name = release_name.replace(\"sae_bench_\", \"\")\n",
    "\n",
    "#     downloaded_dir = snapshot_download(\n",
    "#         repo_id, allow_patterns=[f\"{folder_name}/*\"], ignore_patterns=[\"*ae.pt\"], local_dir=\"\", force_download=True\n",
    "#     )\n",
    "\n",
    "#     print(f\"Folder downloaded to {downloaded_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "\n",
    "def get_nested_folders(path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Recursively get a list of folders that contain an ae.pt file, starting the search from the given path\n",
    "    \"\"\"\n",
    "    folder_names = []\n",
    "\n",
    "    # We use config.json so it also works for data folders\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if \"config.json\" in files:\n",
    "            folder_names.append(root)\n",
    "\n",
    "    return folder_names\n",
    "\n",
    "\n",
    "def check_for_empty_folders(ae_group_paths: list[str]) -> bool:\n",
    "    \"\"\"So your run doesn't crash / do nothing interesting because folder 13 is empty.\"\"\"\n",
    "    for ae_group_path in ae_group_paths:\n",
    "        if len(get_nested_folders(ae_group_path)) == 0:\n",
    "            raise ValueError(f\"No folders found in {ae_group_path}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_ae_group_paths(\n",
    "    dictionaries_path: str, sweep_name: str, submodule_trainers: Optional[dict]\n",
    ") -> list[str]:\n",
    "    if submodule_trainers is None:\n",
    "        return [f\"{dictionaries_path}/{sweep_name}\"]\n",
    "\n",
    "    ae_group_paths = []\n",
    "\n",
    "    for submodule in submodule_trainers.keys():\n",
    "        trainer_ids = submodule_trainers[submodule][\"trainer_ids\"]\n",
    "\n",
    "        base_filename = f\"{dictionaries_path}/{sweep_name}/{submodule}\"\n",
    "\n",
    "        if trainer_ids is None:\n",
    "            ae_group_paths.append(base_filename)\n",
    "        else:\n",
    "            for trainer_id in trainer_ids:\n",
    "                ae_group_paths.append(f\"{base_filename}/trainer_{trainer_id}\")\n",
    "\n",
    "    check_for_empty_folders(ae_group_paths)\n",
    "\n",
    "    return ae_group_paths\n",
    "\n",
    "\n",
    "def get_ae_paths(ae_group_paths: list[str]) -> list[str]:\n",
    "    ae_paths = []\n",
    "    for ae_group_path in ae_group_paths:\n",
    "        ae_paths.extend(get_nested_folders(ae_group_path))\n",
    "    return ae_paths\n",
    "\n",
    "\n",
    "for release_name in release_names:\n",
    "    folder_name = release_name.replace(\"sae_bench_\", \"\")\n",
    "    ae_group_paths = get_ae_group_paths(\".\", folder_name, None)\n",
    "    ae_paths = get_ae_paths(ae_group_paths)\n",
    "\n",
    "    release_results_dict = {\"sae_config_dictionary_learning\": {}, \"basic_eval_results\": {}}\n",
    "\n",
    "    for ae_path in ae_paths:\n",
    "        print(ae_path)\n",
    "\n",
    "        config_path = os.path.join(ae_path, \"config.json\")\n",
    "        eval_results_path = os.path.join(ae_path, \"eval_results.json\")\n",
    "\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        with open(eval_results_path, \"r\") as f:\n",
    "            eval_results = json.load(f)\n",
    "\n",
    "        ae_name = ae_path.replace(\"./\", \"\")\n",
    "\n",
    "        release_results_dict[\"sae_config_dictionary_learning\"][ae_name] = config\n",
    "        release_results_dict[\"basic_eval_results\"][ae_name] = eval_results\n",
    "\n",
    "    with open(f\"{release_name}_data.json\", \"w\") as f:\n",
    "        json.dump(release_results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional to download multiple layers conveniently\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "repo_id = \"adamkarvonen/gemma-2-2b-jumprelu\"\n",
    "\n",
    "\n",
    "release_names = [\"gemma-2-2b_sweep_jumprelu_0902\"]\n",
    "\n",
    "for release_name in release_names:\n",
    "    folder_name = release_name.replace(\"sae_bench_\", \"\")\n",
    "\n",
    "    downloaded_dir = snapshot_download(\n",
    "        repo_id,\n",
    "        allow_patterns=[f\"*\"],\n",
    "        ignore_patterns=[\"*ae.pt\"],\n",
    "        local_dir=\"\",\n",
    "        force_download=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Folder downloaded to {downloaded_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "release_names = [\"gemma-2-2b_sweep_jumprelu_0902\"]\n",
    "\n",
    "l0_dict = {\n",
    "    3: [14, 28, 59, 142, 315],\n",
    "    7: [20, 36, 69, 137, 285],\n",
    "    11: [22, 41, 80, 168, 393],\n",
    "    15: [23, 41, 78, 150, 308],\n",
    "    19: [23, 40, 73, 137, 279]\n",
    "}\n",
    "\n",
    "\n",
    "def extract_trainer_and_layer(input_string: str) -> tuple[int, int]:\n",
    "    pattern = r\"gemma-\\d+-\\d+b_sweep_jumprelu_\\d+/resid_post_layer_(\\d+)/trainer_(\\d+)\"\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    if match:\n",
    "        layer_num = int(match.group(1))\n",
    "        trainer_num = int(match.group(2))\n",
    "        return trainer_num, layer_num\n",
    "    else:\n",
    "        raise ValueError(\"Input string does not match the expected format\")\n",
    "\n",
    "\n",
    "def get_nested_folders(path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Recursively get a list of folders that contain an ae.pt file, starting the search from the given path\n",
    "    \"\"\"\n",
    "    folder_names = []\n",
    "\n",
    "    # We use config.json so it also works for data folders\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if \"config.json\" in files:\n",
    "            folder_names.append(root)\n",
    "\n",
    "    return folder_names\n",
    "\n",
    "\n",
    "def check_for_empty_folders(ae_group_paths: list[str]) -> bool:\n",
    "    \"\"\"So your run doesn't crash / do nothing interesting because folder 13 is empty.\"\"\"\n",
    "    for ae_group_path in ae_group_paths:\n",
    "        if len(get_nested_folders(ae_group_path)) == 0:\n",
    "            raise ValueError(f\"No folders found in {ae_group_path}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_ae_group_paths(\n",
    "    dictionaries_path: str, sweep_name: str, submodule_trainers: Optional[dict]\n",
    ") -> list[str]:\n",
    "    if submodule_trainers is None:\n",
    "        return [f\"{dictionaries_path}/{sweep_name}\"]\n",
    "\n",
    "    ae_group_paths = []\n",
    "\n",
    "    for submodule in submodule_trainers.keys():\n",
    "        trainer_ids = submodule_trainers[submodule][\"trainer_ids\"]\n",
    "\n",
    "        base_filename = f\"{dictionaries_path}/{sweep_name}/{submodule}\"\n",
    "\n",
    "        if trainer_ids is None:\n",
    "            ae_group_paths.append(base_filename)\n",
    "        else:\n",
    "            for trainer_id in trainer_ids:\n",
    "                ae_group_paths.append(f\"{base_filename}/trainer_{trainer_id}\")\n",
    "\n",
    "    check_for_empty_folders(ae_group_paths)\n",
    "\n",
    "    return ae_group_paths\n",
    "\n",
    "\n",
    "def get_ae_paths(ae_group_paths: list[str]) -> list[str]:\n",
    "    ae_paths = []\n",
    "    for ae_group_path in ae_group_paths:\n",
    "        ae_paths.extend(get_nested_folders(ae_group_path))\n",
    "    return ae_paths\n",
    "\n",
    "\n",
    "for release_name in release_names:\n",
    "    folder_name = release_name.replace(\"sae_bench_\", \"\")\n",
    "    ae_group_paths = get_ae_group_paths(\".\", folder_name, None)\n",
    "    ae_paths = get_ae_paths(ae_group_paths)\n",
    "\n",
    "    print(ae_paths)\n",
    "\n",
    "    release_results_dict = {\"sae_config_dictionary_learning\": {}, \"basic_eval_results\": {}}\n",
    "\n",
    "    for ae_path in ae_paths:\n",
    "        print(ae_path)\n",
    "\n",
    "        config_path = os.path.join(ae_path, \"config.json\")\n",
    "        eval_results_path = os.path.join(ae_path, \"eval_results.json\")\n",
    "\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        with open(eval_results_path, \"r\") as f:\n",
    "            eval_results = json.load(f)\n",
    "\n",
    "        ae_name = ae_path.replace(\"./\", \"\")\n",
    "\n",
    "        trainer_id, layer_num = extract_trainer_and_layer(ae_name)\n",
    "\n",
    "        print(ae_name, trainer_id, layer_num)\n",
    "\n",
    "        formatted_name = f\"layer_{layer_num}/width_16k/average_l0_{l0_dict[layer_num][trainer_id]}\"\n",
    "\n",
    "        print(formatted_name)\n",
    "\n",
    "        release_results_dict[\"sae_config_dictionary_learning\"][formatted_name] = config\n",
    "        release_results_dict[\"basic_eval_results\"][formatted_name] = eval_results\n",
    "\n",
    "    with open(f\"gemma-scope-2b-pt-res_data.json\", \"w\") as f:\n",
    "        json.dump(release_results_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
